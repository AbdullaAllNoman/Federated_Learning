{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38187e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from keras.datasets import mnist\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "918ad204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "covid = glob.glob('Dataset0.1/training/covid/*.*')\n",
    "normal = glob.glob('Dataset0.1/training/normal/*.*')\n",
    "pneumonia = glob.glob('Dataset0.1/training/pneumonia/*.*')\n",
    "tuberculosis = glob.glob('Dataset0.1/training/tuberculosis/*.*')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in covid:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (150,150))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in normal:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (150,150))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "for i in pneumonia:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (150,150))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(2)\n",
    "for i in tuberculosis:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (150,150))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(3)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb60c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(data, labels, test_size=0.2,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e68667ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 150, 150)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56d63a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6087710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 150, 150)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "164d0195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n"
     ]
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b75891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_valid = np.reshape(x_valid, [-1, input_size])\n",
    "x_valid = x_valid.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2853dc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2160, 22500), (2160,), (720, 22500), (720,), (720, 22500), (720,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape , x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "54854131",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = torch.from_numpy(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29b0596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.from_numpy(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "017b444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13b5bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c75c566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 >> train: tensor(581) , valid: tensor(198) , test: tensor(221) , total: tensor(1000)\n",
      "1 >> train: tensor(590) , valid: tensor(216) , test: tensor(194) , total: tensor(1000)\n",
      "2 >> train: tensor(490) , valid: tensor(153) , test: tensor(157) , total: tensor(800)\n",
      "3 >> train: tensor(499) , valid: tensor(153) , test: tensor(148) , total: tensor(800)\n",
      "y_train_total= tensor(2160)\n",
      "y_valid_total= tensor(720)\n",
      "y_test_total= tensor(720)\n",
      "total= tensor(3600)\n"
     ]
    }
   ],
   "source": [
    "# Let's check how many of each tag are.\n",
    "y_train_total=0\n",
    "y_valid_total=0\n",
    "y_test_total=0\n",
    "total=0\n",
    "for i in range(4):\n",
    "    print(i,\">> train:\", sum(y_train==i), \", valid:\", sum(y_valid==i), \n",
    "          \", test:\", sum(y_test==i), \", total:\", sum(y_train==i)+sum(y_valid==i)+sum(y_test==i) )\n",
    "    y_train_total=y_train_total + sum(y_train==i)\n",
    "    y_valid_total=y_valid_total + sum(y_valid==i)\n",
    "    y_test_total=y_test_total + sum(y_test==i)\n",
    "    total=total+sum(y_train==i)+sum(y_valid==i)+sum(y_test==i)\n",
    "    \n",
    "print(\"y_train_total=\", y_train_total) \n",
    "print(\"y_valid_total=\", y_valid_total) \n",
    "print(\"y_test_total=\", y_test_total)\n",
    "print(\"total=\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f67eea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2nn(nn.Module):\n",
    "    def __init__(self,n_features):\n",
    "        super(Net2nn, self).__init__()\n",
    "        self.fc1=nn.Linear(n_features,2048)\n",
    "        self.fc2=nn.Linear(2048,512)\n",
    "        self.fc3=nn.Linear(512,128)\n",
    "        self.fc4=nn.Linear(128,32)\n",
    "        self.fc5=nn.Linear(32,4)\n",
    "        #self.fc6=nn.Linear(128,64)\n",
    "        #self.fc7=nn.Linear(64,4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=F.relu(self.fc4(x))\n",
    "        #x=F.relu(self.fc5(x))\n",
    "        #x=F.relu(self.fc6(x))\n",
    "        x=self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd1f3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2160, 22500]) torch.Size([2160])\n",
      "torch.Size([720, 22500]) torch.Size([720])\n",
      "torch.Size([720, 22500]) torch.Size([720])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d82f0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_model = Net2nn(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "724db2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net2nn(\n",
       "  (fc1): Linear(in_features=22500, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc5): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralized_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3dda1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.0005, momentum=0.9)\n",
    "centralized_criterion = nn.CrossEntropyLoss()\n",
    "#centralized_criterion = nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8a03b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3141ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = torch.from_numpy(x_train).float()\n",
    "#y_train = torch.squeeze(torch.from_numpy(y_train).float())\n",
    "#x_test = torch.from_numpy(x_test).float()\n",
    "#y_test = torch.squeeze(torch.from_numpy(y_test).float())\n",
    "#x_valid = torch.from_numpy(x_valid).float()\n",
    "#y_valid = torch.squeeze(torch.from_numpy(y_valid).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9f61f9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e406dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "x_valid = x_valid.to(device)\n",
    "y_valid = y_valid.to(device)\n",
    "\n",
    "centralized_model = centralized_model.to(device)\n",
    "centralized_criterion = centralized_criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf664a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        \n",
    "\n",
    "    return train_loss / len(train_loader), correct/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9308499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target.long()).item()\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "135ccf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "numEpoch = 50\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35e3401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Centralized Model ------\n",
      "epoch:   1 | train accuracy:  0.3319 | test accuracy:  0.3875\n",
      "epoch:   2 | train accuracy:  0.3741 | test accuracy:  0.3833\n",
      "epoch:   3 | train accuracy:  0.3745 | test accuracy:  0.3986\n",
      "epoch:   4 | train accuracy:  0.3968 | test accuracy:  0.4472\n",
      "epoch:   5 | train accuracy:  0.4421 | test accuracy:  0.5111\n",
      "epoch:   6 | train accuracy:  0.4606 | test accuracy:  0.5167\n",
      "epoch:   7 | train accuracy:  0.4907 | test accuracy:  0.5208\n",
      "epoch:   8 | train accuracy:  0.5435 | test accuracy:  0.5972\n",
      "epoch:   9 | train accuracy:  0.6162 | test accuracy:  0.6194\n",
      "epoch:  10 | train accuracy:  0.6653 | test accuracy:  0.6583\n",
      "epoch:  11 | train accuracy:  0.6736 | test accuracy:  0.6653\n",
      "epoch:  12 | train accuracy:  0.6995 | test accuracy:  0.6472\n",
      "epoch:  13 | train accuracy:  0.7185 | test accuracy:  0.7000\n",
      "epoch:  14 | train accuracy:  0.7389 | test accuracy:  0.7181\n",
      "epoch:  15 | train accuracy:  0.7481 | test accuracy:  0.7208\n",
      "epoch:  16 | train accuracy:  0.7579 | test accuracy:  0.7181\n",
      "epoch:  17 | train accuracy:  0.7579 | test accuracy:  0.7375\n",
      "epoch:  18 | train accuracy:  0.7616 | test accuracy:  0.7333\n",
      "epoch:  19 | train accuracy:  0.7657 | test accuracy:  0.7208\n",
      "epoch:  20 | train accuracy:  0.7764 | test accuracy:  0.7403\n",
      "epoch:  21 | train accuracy:  0.7741 | test accuracy:  0.7125\n",
      "epoch:  22 | train accuracy:  0.7796 | test accuracy:  0.7486\n",
      "epoch:  23 | train accuracy:  0.7912 | test accuracy:  0.7444\n",
      "epoch:  24 | train accuracy:  0.7884 | test accuracy:  0.7514\n",
      "epoch:  25 | train accuracy:  0.7861 | test accuracy:  0.7444\n",
      "epoch:  26 | train accuracy:  0.7940 | test accuracy:  0.7625\n",
      "epoch:  27 | train accuracy:  0.7949 | test accuracy:  0.7667\n",
      "epoch:  28 | train accuracy:  0.8106 | test accuracy:  0.7667\n",
      "epoch:  29 | train accuracy:  0.8005 | test accuracy:  0.7681\n",
      "epoch:  30 | train accuracy:  0.8056 | test accuracy:  0.7611\n",
      "epoch:  31 | train accuracy:  0.8167 | test accuracy:  0.7806\n",
      "epoch:  32 | train accuracy:  0.8130 | test accuracy:  0.7458\n",
      "epoch:  33 | train accuracy:  0.8106 | test accuracy:  0.7708\n",
      "epoch:  34 | train accuracy:  0.8144 | test accuracy:  0.7778\n",
      "epoch:  35 | train accuracy:  0.8153 | test accuracy:  0.7500\n",
      "epoch:  36 | train accuracy:  0.8171 | test accuracy:  0.7819\n",
      "epoch:  37 | train accuracy:  0.8213 | test accuracy:  0.7139\n",
      "epoch:  38 | train accuracy:  0.7995 | test accuracy:  0.7958\n",
      "epoch:  39 | train accuracy:  0.8319 | test accuracy:  0.7931\n",
      "epoch:  40 | train accuracy:  0.8236 | test accuracy:  0.7889\n",
      "epoch:  41 | train accuracy:  0.8366 | test accuracy:  0.7931\n",
      "epoch:  42 | train accuracy:  0.8421 | test accuracy:  0.7958\n",
      "epoch:  43 | train accuracy:  0.8324 | test accuracy:  0.8056\n",
      "epoch:  44 | train accuracy:  0.8426 | test accuracy:  0.8069\n",
      "epoch:  45 | train accuracy:  0.8463 | test accuracy:  0.8097\n",
      "epoch:  46 | train accuracy:  0.8431 | test accuracy:  0.7889\n",
      "epoch:  47 | train accuracy:  0.8477 | test accuracy:  0.7847\n",
      "epoch:  48 | train accuracy:  0.8319 | test accuracy:  0.8069\n",
      "epoch:  49 | train accuracy:  0.8514 | test accuracy:  0.8083\n",
      "epoch:  50 | train accuracy:  0.8537 | test accuracy:  0.8139\n",
      "------ Training finished ------\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Centralized Model ------\")\n",
    "for epoch in range(numEpoch):\n",
    "    central_train_loss, central_train_accuracy = train(centralized_model, train_dl, centralized_criterion, centralized_optimizer)\n",
    "    central_test_loss, central_test_accuracy = validation(centralized_model, test_dl, centralized_criterion)\n",
    "    \n",
    "    print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.4f}\".format(central_train_accuracy) + \" | test accuracy: {:7.4f}\".format(central_test_accuracy))\n",
    "\n",
    "print(\"------ Training finished ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c7264e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_dl:\n",
    "        output = centralized_model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = ('c', 'n', 'p', 'tb')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix)*720, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3d0da416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "12772ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        \n",
    "        #yhat = yhat.cpu().data.numpy().argmax()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b43130dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-1f5a715c4d63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentralized_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-ad1a67465e9f>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(test_dl, model)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# retrieve numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#yhat = yhat.cpu().data.numpy().argmax()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "evaluate_model(test_dl, centralized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a15ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b2d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
